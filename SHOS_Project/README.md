Copie ce code dans ton fichier main.py.

Assure-toi d'√™tre dans ton environnement avec source ~/venv/bin/activate

Lance avec python3 main.py

Ouvre ton navigateur sur http://localhost:5000


./start_shos.sh







#include <Wire.h>
#include <LiquidCrystal_I2C.h>
#include <RTClib.h>
#include <DHT.h>

// --- CONFIGURATION PINS ---
#define TRIG_PIN 2
#define ECHO_PIN 3
#define JOY_BTN 4
#define DHT_PIN 5
#define FISH_PIN 6  // Capteur obstacle IR
#define LIGHT_PIN 7
#define BUZZER_PIN 9
#define VIBREUR_PIN 10
#define RGB_R 11
#define RGB_G 12
#define RGB_B 13
#define JOY_X A0
#define JOY_Y A1
#define GAS_PIN A2
#define SOUND_PIN A3

// --- OBJETS ---
DHT dht(DHT_PIN, DHT11);
LiquidCrystal_I2C lcd(0x27, 16, 2); // Adresse I2C 0x27 ou 0x3F
RTC_DS3231 rtc;

void setup() {
  Serial.begin(115200);
  
  // Initialisation capteurs/actuateurs
  dht.begin();
  lcd.init();
  lcd.backlight();
  if (!rtc.begin()) { /* RTC non trouv√© */ }

  pinMode(TRIG_PIN, OUTPUT);
  pinMode(ECHO_PIN, INPUT);
  pinMode(JOY_BTN, INPUT_PULLUP);
  pinMode(FISH_PIN, INPUT);
  pinMode(LIGHT_PIN, INPUT);
  pinMode(BUZZER_PIN, OUTPUT);
  pinMode(VIBREUR_PIN, OUTPUT);
  pinMode(RGB_R, OUTPUT);
  pinMode(RGB_G, OUTPUT);
  pinMode(RGB_B, OUTPUT);

  lcd.setCursor(0,0);
  lcd.print("SmartGlasses OS");
}

void loop() {
  // 1. DISTANCE ULTRASON
  digitalWrite(TRIG_PIN, LOW); delayMicroseconds(2);
  digitalWrite(TRIG_PIN, HIGH); delayMicroseconds(10);
  digitalWrite(TRIG_PIN, LOW);
  long dist = pulseIn(ECHO_PIN, HIGH) * 0.034 / 2;

  // 2. ENVIRONNEMENT
  float h = dht.readHumidity();
  float t = dht.readTemperature();
  int gas = analogRead(GAS_PIN);
  int sound = analogRead(SOUND_PIN);
  int ir_obs = digitalRead(FISH_PIN); // 0 si obstacle, 1 si rien
  int light = digitalRead(LIGHT_PIN); 

  // 3. JOYSTICK
  int x = analogRead(JOY_X);
  int y = analogRead(JOY_Y);
  int btn = !digitalRead(JOY_BTN); // Invers√© car Pullup

  // 4. TEMPS (RTC)
  DateTime now = rtc.now();

  // 5. AFFICHAGE LCD (Local)
  lcd.setCursor(0,1);
  lcd.print(dist); lcd.print("cm ");
  lcd.print(t, 0); lcd.print("C  ");
  lcd.print(now.hour()); lcd.print(":"); lcd.print(now.minute());

  // 6. LOGIQUE DE S√âCURIT√â (Feedback direct)
  if (gas > 400 || dist < 15) {
    digitalWrite(VIBREUR_PIN, HIGH);
    digitalWrite(RGB_R, HIGH);
    digitalWrite(RGB_B, LOW);
  } else {
    digitalWrite(VIBREUR_PIN, LOW);
    digitalWrite(RGB_R, LOW);
    digitalWrite(RGB_G, HIGH); // Vert si tout va bien
  }

  // 7. ENVOI JSON VERS PYTHON
  Serial.print("{");
  Serial.print("\"dist\":"); Serial.print(dist);
  Serial.print(",\"gas\":"); Serial.print(gas);
  Serial.print(",\"temp_ext\":"); Serial.print(isnan(t) ? 0 : t);
  Serial.print(",\"hum\":"); Serial.print(isnan(h) ? 0 : h);
  Serial.print(",\"son\":"); Serial.print(sound);
  Serial.print(",\"lum\":"); Serial.print(light);
  Serial.print(",\"joy_x\":"); Serial.print(x);
  Serial.print(",\"joy_y\":"); Serial.print(y);
  Serial.print(",\"btn\":"); Serial.print(btn);
  Serial.print(",\"obs\":"); Serial.print(ir_obs);
  Serial.print(",\"time\":\""); Serial.print(now.hour()); Serial.print(":"); Serial.print(now.minute()); Serial.print("\"");
  Serial.println("}");

  delay(500);





























PROJET : S.H.O.S (Smart Helmet Operating System)
Syst√®me d'Exploitation Modulaire pour Casque de R√©alit√© Augment√©e Industriel & Assistance

1. üéØ Vision et Objectifs
Le projet consiste √† concevoir un casque intelligent int√©gral (type VR/AR pass-through) autonome. Contrairement √† des lunettes l√©g√®res, ce casque embarque une puissance de calcul compl√®te et une multitude de capteurs pour des environnements complexes (mines, usines) ou pour l'assistance au handicap.

Philosophie : Le syst√®me fonctionne comme un OS (Syst√®me d'Exploitation). Il ne fait rien tout seul, mais il fournit les ressources (vid√©o, capteurs, r√©seau) √† des Plugins que l'utilisateur active selon son Profil (Mineur, Navigation, Maintenance, etc.).

2. üèóÔ∏è Architecture Mat√©rielle (Le Casque)
Le casque est un dispositif autonome qui int√®gre l'informatique, la vision et l'√©nergie.

A. Le C≈ìur (Unit√©s de Calcul)
Cerveau Principal (Master) : Raspberry Pi 4 ou 5.

R√¥le : H√©berge l'OS, le Backbone, le serveur MQTT, le traitement vid√©o et l'IA.

OS : Raspberry Pi OS (Bookworm).

Cerveau Sensoriel (Slave) : Arduino (Nano/Uno) connect√© en USB (/dev/ttyUSB0).

R√¥le : Interface bas niveau. Il lit les capteurs analogiques/num√©riques en temps r√©el et envoie les donn√©es brutes √† la Pi via S√©rie (Serial).

B. Les Organes (P√©riph√©riques)
Vision : Module Cam√©ra Pi (Connecteur CSI) ou Webcam USB grand angle.

Affichage (HUD) : √âcran interne du casque (HDMI ou DSI) affichant l'interface web en plein √©cran (Mode Kiosque).

Capteurs (Liste √©volutive connect√©e √† l'Arduino) :

Distance (Ultrasons/LiDAR) : Pour la d√©tection d'obstacles.

Environnement : DHT11/22 (Temp√©rature/Humidit√©), MQ-x (Gaz toxiques/Fum√©e).

Position : Module GPS (Latitude/Longitude).

Mouvement : Acc√©l√©rom√®tre/Gyroscope (Orientation de la t√™te).

√ânergie : Power Bank haute capacit√© (5V/3A min) int√©gr√©e √† l'arri√®re du casque (contrepoids).

3. üß† Architecture Logicielle (Le Backbone)
C'est une architecture Micro-Services bas√©e sur un bus de donn√©es.

A. Le Concept "Backbone" (Colonne Vert√©brale)
Le script backbone.py est le seul ma√Ætre √† bord. Il se lance au d√©marrage.

Il ne r√©fl√©chit pas. (Pas d'IA).

Il fournit. Il capture le flux vid√©o et les donn√©es Arduino.

Il distribue. Il publie tout sur le r√©seau local interne via MQTT.

B. Le Protocole de Communication (MQTT)
Le syst√®me nerveux du casque est le protocole MQTT (Message Queuing Telemetry Transport). Tout passe par l√† via un "Broker" (Mosquitto) install√© sur la Pi.

Structure des "Topics" (Canaux de discussion) :

helmet/system/control : Commandes (Changer de profil, Arr√™t d'urgence).

helmet/camera/raw : Flux vid√©o brut (MJPEG binaire).

helmet/sensors/all : JSON contenant toutes les valeurs capteurs {temp: 24, gaz: 10, dist: 150}.

helmet/plugins/[nom_du_plugin]/data : R√©sultats des modules (ex: helmet/plugins/vision/detections).

4. üß© Le Syst√®me de Plugins & Profils
Le syst√®me est "agnostique". Il ne sait pas ce qu'il doit faire tant qu'un Profil n'est pas charg√©.

A. Dossier /plugins
Chaque fonctionnalit√© est un dossier ind√©pendant.

Exemple : /plugins/vision_objet/

Contient main.py : S'abonne √† helmet/camera/raw, charge YOLO, d√©tecte, publie sur MQTT.

Contient widget.html : Code HTML/JS pour afficher le carr√© rouge sur l'√©cran.

B. Dossier /modeles
Stockage centralis√© des cerveaux IA (yolov8n.pt, ocr_model.tflite, etc.). Les plugins viennent piocher ici.

C. Les Profils Utilisateurs (profiles.json)
C'est le fichier qui d√©finit l'usage du casque.

Sc√©nario 1 : Profil "Navigation (Aveugle)"

Modules activ√©s : vision_objet, gps, audio_guide.

Comportement : Le casque ignore le capteur de gaz. Il lance l'IA de vision.

Sc√©nario 2 : Profil "Industrie (Mineur)"

Modules activ√©s : gaz_monitor, environment, remote_assist, flashlight.

Comportement : Le casque coupe l'IA de vision (√©conomie batterie/CPU). Il surveille le CO2 en priorit√©. Si le seuil est d√©pass√©, il affiche une alerte rouge.

5. üñ•Ô∏è L'Interface Utilisateur (HUD)
L'affichage dans le casque n'est pas une simple vid√©o. C'est une page Web (Flask) en temps r√©el.

A. Le HUD (Heads-Up Display)
Fond d'√©cran : Le flux vid√©o cam√©ra (faible latence).

Calque Widgets : Par-dessus la vid√©o, des √©l√©ments HTML (divs) s'affichent ou se cachent selon les messages MQTT re√ßus.

Widget Vision : Dessine les cadres (Bounding Boxes) re√ßus du plugin Vision.

Widget Danger : Clignote en rouge si le plugin Gaz envoie une alerte.

Widget Syst√®me : Affiche CPU, Batterie, Heure.

B. Le Panneau de Contr√¥le (Web Interface)
Accessible via un navigateur externe (Smartphone/Tablette compagnon) ou via commandes vocales.

Permet de s√©lectionner le Profil.

Permet d'activer/d√©sactiver un module manuellement ("Toggle").

Affiche l'√©tat de sant√© du syst√®me (Logs).

6. üõ†Ô∏è Guide du D√©veloppeur : Comment √©tendre le syst√®me ?
Voici la proc√©dure stricte pour ajouter des fonctionnalit√©s sans casser le syst√®me existant.

Cas Pratique 1 : Ajouter un nouveau capteur (ex: Geiger/Radiation)
Hardware : Connecter le capteur au Arduino.

Code Arduino : Ajouter la lecture dans la boucle et l'envoyer sur le port S√©rie (format JSON : {"rad": 120}).

Backbone (Pi) : Rien √† faire ! Le Backbone lit tout le JSON de l'Arduino et le republie sur helmet/sensors/all.

Interface : Cr√©er un petit widget HTML qui √©coute helmet/sensors/all et affiche la valeur "rad".

Cas Pratique 2 : Ajouter une nouvelle IA (ex: Lecture de panneaux)
Mod√®le : D√©poser ocr_traffic.pt dans le dossier /modeles.

Plugin : Cr√©er le dossier /plugins/lecteur_panneaux.

Code Python (main.py) :

Se connecter au MQTT (localhost).

S'abonner √† helmet/camera/raw.

Charger le mod√®le depuis ../../modeles/ocr_traffic.pt.

Traiter l'image.

Publier le texte lu sur helmet/plugins/lecteur_panneaux/text.

Activation : Ajouter "lecteur_panneaux" dans le fichier profiles.json sous le profil "Navigation".

7. üöÄ R√©sum√© du Flux de Donn√©es (Data Flow)
Le Monde R√©el -> Capteurs/Cam√©ra.

Acquisition -> Arduino (Capteurs) / Libcamera (Vid√©o).

Centralisation -> Backbone.py (Raspberry Pi).

Distribution -> MQTT Broker (Le Backbone publie tout).

Traitement -> Les Plugins (Vision, GPS...) √©coutent MQTT, calculent, et republient les r√©sultats.

Visualisation -> Le HUD (Navigateur Web dans le casque) √©coute MQTT et met √† jour l'affichage graphique par-dessus la vid√©o.












1. üèóÔ∏è Architecture Mat√©rielle (Hardware)Le syst√®me est divis√© en deux cerveaux : le Calcul (Haut Niveau) et le Sensoriel (Bas Niveau).A. Le Diagramme de ConnexionPlaintext       [ BATTERIE EXT (5V/3A) ]
                  |
        +---------+---------+
        |                   |
  [ RASPBERRY PI 5 ] <---> [ ARDUINO NANO/UNO ] (via USB)
  (Cerveau Principal)      (Cerveau Sensoriel)
        |                           |
        +-- [ CAM√âRA CSI ]          +-- [ Capteur Distance (HC-SR04) ]
        |                           |
        +-- [ √âCRAN HUD (HDMI) ]    +-- [ Capteur Gaz (MQ-2) ]
        |                           |
        +-- [ CASQUE AUDIO ]        +-- [ Temp√©rature (DHT22) ]
                                    |
                                    +-- [ GPS Module (NEO-6M) ]
B. R√¥les Mat√©rielsRaspberry Pi (Master) : G√®re l'OS, le r√©seau (Wi-Fi/MQTT), l'affichage vid√©o, et les calculs d'Intelligence Artificielle (YOLO).Arduino (Slave) : G√®re l'acquisition de donn√©es brutes. Il nettoie les signaux des capteurs et envoie un paquet JSON propre √† la Pi chaque 100ms.2. üíª Architecture Logicielle (Software Stack)Le syst√®me repose sur une architecture Micro-Services asynchrone.CoucheTechnologieR√¥leInterface (UI)HTML5 / JS / SocketIOAffichage t√™te haute (HUD) et Contr√¥leCommunicationMQTT (Mosquitto)Bus de donn√©es universel (Le "Nerf" du syst√®me)OrchestrationPython (Backbone.py)Gestion des processus et des ProfilsIntelligencePython (Plugins)Modules ind√©pendants (Vision, Nav, Danger)Syst√®meLinux (Debian Bookworm)Gestion drivers Cam√©ra (Libcamera) & USB3. üìÇ Arborescence du Projet (File Structure)Voici comment organiser tes dossiers pour que le syst√®me soit propre et modulaire.PlaintextSHOS_Project/
‚îÇ
‚îú‚îÄ‚îÄ backbone.py           # LE MA√éTRE : Lance les profils, g√®re le hardware, publie sur MQTT
‚îú‚îÄ‚îÄ profiles.json         # CONFIG : D√©finit quels plugins lancer pour "Mine", "Ville", etc.
‚îú‚îÄ‚îÄ requirements.txt      # D√âPENDANCES : Liste des librairies (flask, paho-mqtt, ultralytics...)
‚îÇ
‚îú‚îÄ‚îÄ modeles/              # CERVEAUX IA (Stockage centralis√©)
‚îÇ   ‚îú‚îÄ‚îÄ yolov8n.pt        # Mod√®le d√©tection objets standard
‚îÇ   ‚îú‚îÄ‚îÄ gaz_risk.tflite   # Mod√®le pr√©diction danger gaz
‚îÇ   ‚îî‚îÄ‚îÄ ocr_text.pt       # Mod√®le lecture de texte
‚îÇ
‚îú‚îÄ‚îÄ plugins/              # LES OUVRIERS (Un dossier = Une fonctionnalit√©)
‚îÇ   ‚îú‚îÄ‚îÄ vision_objet/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py       # Code du plugin (S'abonne √† Camera, publie Detections)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.json   # Param√®tres sp√©cifiques (ex: seuil de confiance)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ navigation_gps/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ maps_cache/   # Dossier local pour cartes hors-ligne
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ danger_monitor/   # (Surveillance Gaz/Temp√©rature)
‚îÇ       ‚îî‚îÄ‚îÄ main.py
‚îÇ
‚îî‚îÄ‚îÄ interface/            # LE VISAGE (Serveur Web Flask)
    ‚îú‚îÄ‚îÄ app.py            # Serveur Web l√©ger
    ‚îú‚îÄ‚îÄ templates/
    ‚îÇ   ‚îî‚îÄ‚îÄ hud.html      # La page vue dans les lunettes
    ‚îî‚îÄ‚îÄ static/
        ‚îú‚îÄ‚îÄ style.css
        ‚îî‚îÄ‚îÄ script.js     # Connecte le HUD au MQTT via Websocket
4. üîÑ Diagramme de Flux de Donn√©es (Data Flow)C'est le chemin que parcourt une information dans ton syst√®me.√âtape 1 : Acquisition (INPUT)Cam√©ra : Capture une image brute (Raw Bytes).Arduino : Lit Temp: 24¬∞C, Gaz: 120ppm.Backbone : R√©cup√®re ces deux flux.√âtape 2 : Distribution (BUS MQTT)Le Backbone ne traite rien. Il crie les infos sur le r√©seau :Publie sur helmet/camera/stream (L'image).Publie sur helmet/sensors/raw (Le JSON Arduino).√âtape 3 : Traitement (PLUGINS)Les plugins actifs (selon le profil) √©coutent :Plugin Vision attrape l'image -> D√©tecte "Personne" -> Publie {"box": [x,y,w,h], "label": "Personne"} sur helmet/vision/out.Plugin Danger attrape le JSON Arduino -> Analyse le gaz -> Si > 200, publie {"alert": "DANGER"} sur helmet/alert.√âtape 4 : Visualisation (OUTPUT)Le HUD (Page Web) √©coute tous les canaux de sortie (/vision/out, /alert, /sensors).Il dessine le cadre rouge sur la vid√©o.Il fait clignoter l'√©cran si alerte gaz.5. ‚öôÔ∏è Le M√©canisme de Profils (Orchestrateur)C'est la logique qui rend le syst√®me "Intelligent" et √©conome en √©nergie.Fichier profiles.json :JSON{
  "exploration_mine": {
    "description": "Priorit√© s√©curit√© et environnement",
    "active_plugins": ["danger_monitor", "flashlight_control", "remote_assist"],
    "camera_fps": 15,
    "ai_model": "none"  // Pas d'IA vision pour √©conomiser la batterie
  },
  "navigation_ville": {
    "description": "Assistance visuelle compl√®te",
    "active_plugins": ["vision_objet", "ocr_lecture", "gps_guide"],
    "camera_fps": 30,
    "ai_model": "yolov8n.pt"
  }
}
Fonctionnement :Au d√©marrage, le syst√®me charge un profil par d√©faut.L'utilisateur dit "Mode Mine" (ou clique sur un bouton).L'Orchestrateur (Backbone) :TUE les processus vision_objet et ocr_lecture (Lib√©ration RAM).LANCE les processus danger_monitor.Change la configuration de la cam√©ra.6. üõ°Ô∏è S√©curit√© et Robustesse (Watchdog)Pour un projet industriel, le syst√®me ne doit jamais planter totalement.Isolation des Processus : Chaque plugin tourne dans son propre coin. Si le plugin Vision crashe (erreur m√©moire), le Backbone le voit, le tue, et le red√©marre, SANS couper la vid√©o ni les capteurs de gaz.Mode "Safe" : Si la batterie descend sous 15%, le Backbone force le profil "√âconomie" (Coupe toutes les IA, garde juste les capteurs vitaux).Logs : Tout est enregistr√© dans un fichier system.log pour comprendre les pannes apr√®s coup.
























non non non ! c'est pas ca la logique ! celui qui donneras l'ordre d'activer les modules c'est le script du profil utilisateur ! les mmodules et les profils sont gerer par le fichier de congiguration ! lui il atribue des modules a un profil ! la configuration as acces a tout les moduules et il les atribue au profil lors de ca cr√©ation par le profil manager !   pour mieu expliquer, l'utilisateur cr√© son profil grace au profil manager ! le profil manager dit  a la configuraion  le profil qui as etait demander et tout les modules qui seront atribuer au profil !   puis la configuration cr√©e le profil avec chacun des modules et capteur dont il a besoin ! puis il le met a la disposition de l'utilisateur sur son interface apreprier pour lui !  et si l'utilisateur cr√©e un autre profil ! tout se fait pareil ! alors sur l'interface utilisateur au depart il n'y as qu'une pages d'aceil ! en suite quand il as cr√©er des profiles, ils aparaissent sur sont interface et il peut en lancer un a un ! et quand il lance un profil, le module pricipale du profil s'active, et le reste peut etre activer ou des activer a partir de l'interface du profil ! tu as des questions ?

}