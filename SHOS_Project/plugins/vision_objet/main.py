import cv2
import numpy as np
from paho.mqtt import client as mqtt_client
import json
import os
from ultralytics import YOLO

# --- CONFIGURATION DES TOPICS ---
TOPIC_CAMERA = "helmet/camera/raw"
TOPIC_CONTROL = "helmet/plugins/vision_objet/control"
TOPIC_GLOBAL = "helmet/plugins/control"
TOPIC_RESULTS = "helmet/plugins/vision_objet/data"

# Chemin vers ton mod√®le (v√©rifie bien que le dossier modeles est au bon endroit)
MODEL_PATH = "../../modeles/yolov8n.pt"

class VisionPlugin:
    def __init__(self):
        print("üß† [VISION] Chargement du mod√®le YOLOv8...")
        self.model = YOLO(MODEL_PATH)
        
        # üö© √âtat initial : d√©sactiv√© pour √©conomiser le Raspberry Pi
        self.active = False 
        
        # Setup MQTT
        self.client = mqtt_client.Client(mqtt_client.CallbackAPIVersion.VERSION2, "PLUGIN_VISION")
        self.client.on_connect = self.on_connect
        self.client.on_message = self.on_message
        
        try:
            self.client.connect("localhost", 1883, 60)
            print("üì° [VISION] Tentative de connexion au Backbone MQTT...")
        except Exception as e:
            print(f"‚ùå [VISION] Erreur de connexion MQTT : {e}")

    def on_connect(self, client, userdata, flags, rc, properties):
        if rc == 0:
            print("‚úÖ [VISION] Connect√© au Backbone. En attente d'activation par profil...")
            # On s'abonne aux flux d'images ET aux deux canaux de contr√¥le
            client.subscribe([
                (TOPIC_CAMERA, 0),
                (TOPIC_CONTROL, 0),
                (TOPIC_GLOBAL, 0)
            ])
        else:
            print(f"‚ùå [VISION] √âchec de connexion, code : {rc}")

    def on_message(self, client, userdata, msg):
        try:
            # 1. GESTION DES COMMANDES (Start / Stop)
            if msg.topic in [TOPIC_CONTROL, TOPIC_GLOBAL]:
                command = json.loads(msg.payload.decode())
                action = command.get("action")
                
                if action == "start":
                    self.active = True
                    print("üöÄ [VISION] Module ACTIV√â")
                elif action in ["stop", "stop_all"]:
                    self.active = False
                    print("üò¥ [VISION] Module mis en PAUSE")
                return

            # 2. TRAITEMENT DE L'IMAGE (Seulement si actif)
            if self.active and msg.topic == TOPIC_CAMERA:
                # V√©rification de la taille du flux pour √©viter les erreurs de d√©codage
                if len(msg.payload) < 500:
                    return

                # D√©codage de l'image re√ßue par MQTT
                nparr = np.frombuffer(msg.payload, np.uint8)
                frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

                if frame is not None and frame.size > 0:
                    # Inf√©rence IA (imgsz=160 pour la rapidit√© sur Pi)
                    results = self.model(frame, stream=True, conf=0.4, verbose=False, imgsz=160)
                    
                    detections = []
                    for r in results:
                        for box in r.boxes:
                            label = self.model.names[int(box.cls[0])]
                            detections.append(label)

                    # Envoi des r√©sultats si on a trouv√© quelque chose
                    if detections:
                        print(f"üéØ [VISION] D√©tect√© : {detections}")
                        output = {
                            "plugin": "vision_objet",
                            "found": detections,
                            "count": len(detections)
                        }
                        self.client.publish(TOPIC_RESULTS, json.dumps(output))

        except Exception as e:
            # On ne print pas l'erreur pour ne pas polluer le terminal en cas de flux saccad√©
            pass

    def run(self):
        # Boucle infinie pour maintenir le plugin en vie
        self.client.loop_forever()

if __name__ == "__main__":
    plugin = VisionPlugin()
    plugin.run()